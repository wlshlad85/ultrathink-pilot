{
  "episode_rewards": [
    -0.021812543921363246,
    0.024083414042308883,
    0.04368348144884221,
    0.008491017028149512,
    0.0038827216651232364,
    0.07283534984851865,
    -0.022671970485475323,
    0.031877906212747616,
    0.03887014146391011,
    0.006777449608802276
  ],
  "episode_returns": [
    -0.21812543921363448,
    0.24083414042308515,
    0.4368348144884182,
    0.08491017028149361,
    0.038827216651227126,
    0.7283534984851903,
    -0.2267197048547498,
    0.3187790621274722,
    0.38870141463909214,
    0.06777449608801334
  ],
  "episode_lengths": [
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273
  ],
  "training_metrics": [
    {
      "loss": 0.5591696053743362,
      "policy_loss": 0.07364490255713463,
      "value_loss": 0.49609196931123734,
      "entropy": 1.0567258894443512
    }
  ]
}