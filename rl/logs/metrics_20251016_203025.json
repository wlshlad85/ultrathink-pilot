{
  "episode_rewards": [
    0.06619044560976325,
    0.04365934608183596,
    -0.003944373912776073,
    0.017144185933431453,
    0.10533905221702444,
    0.05845613714445205,
    -0.08250746351221318,
    0.03446925474588063,
    0.03488026055411318,
    -0.09087733044476771,
    -0.012216891914552247,
    0.028368463877940682,
    0.024944042218568184,
    0.10413626529135654,
    0.04087697097539496,
    0.10713708187351445,
    -0.024052171287039507,
    0.049630320035037596,
    0.0814920868340414,
    0.03185179308466032,
    0.0016987712448069928,
    -0.01860793211589334,
    0.030395553186554743,
    -0.016245689925279302,
    -0.03463625173575418,
    0.08801187548052546,
    0.023780657097382953,
    0.08395112185606414,
    -0.03501614870528866,
    0.009415001538513752
  ],
  "episode_returns": [
    0.6619044560976395,
    0.4365934608183686,
    -0.039443739127764665,
    0.17144185933430922,
    1.0533905221702389,
    0.5845613714445141,
    -0.8250746351221361,
    0.3446925474588136,
    0.34880260554113196,
    -0.9087733044476742,
    -0.12216891914552663,
    0.2836846387794134,
    0.24944042218568718,
    1.0413626529135689,
    0.4087697097539422,
    1.07137081873514,
    -0.2405217128704007,
    0.49630320035036757,
    0.8149208683404074,
    0.31851793084660684,
    0.016987712448068848,
    -0.18607932115893844,
    0.3039555318655518,
    -0.16245689925279416,
    -0.34636251735754575,
    0.880118754805248,
    0.23780657097383084,
    0.8395112185606513,
    -0.3501614870528913,
    0.09415001538513046
  ],
  "episode_lengths": [
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272
  ],
  "training_metrics": [
    {
      "loss": 0.4519566595554352,
      "policy_loss": -0.01988979708403349,
      "value_loss": 0.48256178200244904,
      "entropy": 1.0715318024158478
    },
    {
      "loss": 0.4584733471274376,
      "policy_loss": -0.005736295133829117,
      "value_loss": 0.4749573692679405,
      "entropy": 1.0747731029987335
    },
    {
      "loss": 0.4596310630440712,
      "policy_loss": -0.0051217349246144295,
      "value_loss": 0.47553277015686035,
      "entropy": 1.077997624874115
    }
  ]
}