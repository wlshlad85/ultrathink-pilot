{
  "episode_rewards": [
    -0.021812543921363246,
    0.024083414042308883,
    0.04368348144884221,
    0.008491017028149512,
    0.0038827216651232364,
    0.07283534984851865,
    -0.022671970485475323,
    0.031877906212747616,
    0.03887014146391011,
    0.006777449608802276,
    0.023141800973091445,
    -0.00829853011593804,
    -0.006009431550175951,
    0.0027287894832261437,
    0.04644696632249251,
    -0.015041248615717628,
    0.03814836720636085,
    0.02027878702120215,
    0.010018143914527908,
    0.02304938945254397
  ],
  "episode_returns": [
    -0.21812543921363448,
    0.24083414042308515,
    0.4368348144884182,
    0.08491017028149361,
    0.038827216651227126,
    0.7283534984851903,
    -0.2267197048547498,
    0.3187790621274722,
    0.38870141463909214,
    0.06777449608801334,
    0.23141800973092153,
    -0.0829853011593773,
    -0.06009431550175748,
    0.027287894832261905,
    0.4644696632249312,
    -0.15041248615718095,
    0.38148367206360945,
    0.20278787021201783,
    0.10018143914527489,
    0.2304938945254298
  ],
  "episode_lengths": [
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273
  ],
  "training_metrics": [
    {
      "loss": 0.5591696053743362,
      "policy_loss": 0.07364490255713463,
      "value_loss": 0.49609196931123734,
      "entropy": 1.0567258894443512
    },
    {
      "loss": 0.42909908294677734,
      "policy_loss": -0.02775029931217432,
      "value_loss": 0.46710987389087677,
      "entropy": 1.0260494947433472
    }
  ]
}