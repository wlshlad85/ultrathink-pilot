{
  "episode_rewards": [
    -0.08729685499287451,
    -0.011275964783696682,
    -0.0013375454003093272,
    0.08434858877145887,
    0.01636913720385929,
    0.06530111592330938,
    -0.023020207810668228,
    0.06524917441283322,
    0.018830006903177137,
    0.04034563330886012,
    0.033680100696228316,
    0.011005814082465041,
    -0.00924145775654759,
    0.040758159099044865,
    -0.009260371553813472,
    -0.03450932752097435,
    -0.03982166064920602,
    0.041171518340709735,
    0.005566814832710953,
    0.2225467403623508
  ],
  "episode_returns": [
    -0.8729685499287432,
    -0.11275964783696857,
    -0.013375454003095033,
    0.8434858877145901,
    0.16369137203859907,
    0.6530111592330856,
    -0.23020207810667825,
    0.6524917441283362,
    0.188300069031766,
    0.4034563330886032,
    0.3368010069622729,
    0.1100581408246537,
    -0.09241457756548055,
    0.4075815909904579,
    -0.09260371553813096,
    -0.3450932752097402,
    -0.39821660649206336,
    0.411715183407102,
    0.055668148327114864,
    2.2254674036235045
  ],
  "episode_lengths": [
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273
  ],
  "training_metrics": [
    {
      "loss": 0.5523743182420731,
      "policy_loss": 0.058379639871418476,
      "value_loss": 0.5047295540571213,
      "entropy": 1.073488026857376
    },
    {
      "loss": 0.4032471030950546,
      "policy_loss": -0.053394539281725883,
      "value_loss": 0.46756426244974136,
      "entropy": 1.0922610759735107
    }
  ]
}