{
  "episode_rewards": [
    0.06619044560976325,
    0.04365934608183596,
    -0.003944373912776073,
    0.017144185933431453,
    0.10533905221702444,
    0.05845613714445205,
    -0.08250746351221318,
    0.03446925474588063,
    0.03488026055411318,
    -0.09087733044476771
  ],
  "episode_returns": [
    0.6619044560976395,
    0.4365934608183686,
    -0.039443739127764665,
    0.17144185933430922,
    1.0533905221702389,
    0.5845613714445141,
    -0.8250746351221361,
    0.3446925474588136,
    0.34880260554113196,
    -0.9087733044476742
  ],
  "episode_lengths": [
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272
  ],
  "training_metrics": [
    {
      "loss": 0.4519566595554352,
      "policy_loss": -0.01988979708403349,
      "value_loss": 0.48256178200244904,
      "entropy": 1.0715318024158478
    }
  ]
}