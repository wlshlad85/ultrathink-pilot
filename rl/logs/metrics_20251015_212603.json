{
  "episode_rewards": [
    0.12068951085702423,
    0.08526775673981464,
    0.06152647678196957,
    -0.01594590301719146,
    -0.003781842707321637,
    0.04324697337379332,
    -0.03974637838730699,
    0.012172630903752006,
    0.019421909275592782,
    -0.006007711493085661
  ],
  "episode_returns": [
    1.2068951085702384,
    0.8526775673981524,
    0.615264767819701,
    -0.15945903017191565,
    -0.037818427073221805,
    0.43246973373793907,
    -0.39746378387307546,
    0.12172630903752868,
    0.19421909275592064,
    -0.060077114930856546
  ],
  "episode_lengths": [
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273
  ],
  "training_metrics": [
    {
      "loss": 0.4792577102780342,
      "policy_loss": 0.0020001139491796494,
      "value_loss": 0.4881938397884369,
      "entropy": 1.093624770641327
    }
  ]
}