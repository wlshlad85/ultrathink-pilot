{
  "episode_rewards": [
    0.08553678884167311,
    0.12030694998078109,
    -0.0015562214787554684,
    0.021809379968253776,
    0.031191534682016932,
    -0.0047122192844545,
    0.006485876842749693,
    0.09850942748737287,
    0.06076282863780505,
    -0.0029613142124479182,
    0.1330161981360056,
    -0.061714067632656945,
    0.27373013233245724,
    0.060761874330397404,
    0.050402981749261375,
    0.06062403891959546,
    0.08531399868689332,
    0.056549967653441155,
    0.1256335561501895,
    0.0906448287561885
  ],
  "episode_returns": [
    0.8553678884167359,
    1.2030694998078184,
    -0.015562214787556705,
    0.2180937996825394,
    0.31191534682017963,
    -0.04712219284453978,
    0.06485876842750038,
    0.9850942748737213,
    0.6076282863780591,
    -0.029613142124473857,
    1.3301619813600452,
    -0.6171406763265663,
    2.73730132332457,
    0.6076187433039726,
    0.5040298174926239,
    0.6062403891959445,
    0.8531399868689338,
    0.5654996765344089,
    1.2563355615018867,
    0.9064482875618785
  ],
  "episode_lengths": [
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272
  ],
  "training_metrics": [
    {
      "loss": 0.5254112854599953,
      "policy_loss": 0.024197384249418974,
      "value_loss": 0.5120212733745575,
      "entropy": 1.0807349383831024
    },
    {
      "loss": 0.5153509080410004,
      "policy_loss": 0.04240815527737141,
      "value_loss": 0.4835551604628563,
      "entropy": 1.0612423717975616
    }
  ]
}