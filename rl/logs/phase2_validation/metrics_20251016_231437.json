{
  "episode_rewards": [
    -0.02182700519383072,
    -0.12790942068158617,
    -0.18047898047562205,
    -0.12243075835615161,
    -0.08968148285454818,
    -0.11008467827421997,
    -0.13672380258388303,
    -0.10457385312573321,
    -0.06650143765325188,
    -0.08964770344338181,
    -0.06273491383339133,
    -0.09641475140639519,
    -0.1047913352973366,
    -0.09963303789159263,
    -0.187074030819346,
    -0.15231801171996912,
    0.10288183332175975,
    0.006033599164841868,
    -0.24350027085539902,
    0.0060544429938803445
  ],
  "episode_returns": [
    -0.2182700519383074,
    -1.2790942068158673,
    -1.8047898047562239,
    -1.2243075835615125,
    -0.896814828545478,
    -1.1008467827422042,
    -1.367238025838824,
    -1.0457385312573342,
    -0.6650143765325245,
    -0.896477034433818,
    -0.6273491383339103,
    -0.964147514063951,
    -1.047913352973362,
    -0.9963303789159217,
    -1.8707403081934637,
    -1.5231801171996961,
    1.028818333217596,
    0.06033599164840808,
    -2.4350027085539905,
    0.06054442993881359
  ],
  "episode_lengths": [
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272,
    272
  ],
  "training_metrics": [
    {
      "loss": 0.45194410532712936,
      "policy_loss": -0.03783366363495588,
      "value_loss": 0.5007074922323227,
      "entropy": 1.0929736196994781
    },
    {
      "loss": 0.44214125722646713,
      "policy_loss": -0.024524488486349583,
      "value_loss": 0.4776053801178932,
      "entropy": 1.093964546918869
    }
  ]
}