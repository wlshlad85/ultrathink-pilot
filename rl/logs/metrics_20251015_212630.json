{
  "episode_rewards": [
    0.12068951085702423,
    0.08526775673981464,
    0.06152647678196957,
    -0.01594590301719146,
    -0.003781842707321637,
    0.04324697337379332,
    -0.03974637838730699,
    0.012172630903752006,
    0.019421909275592782,
    -0.006007711493085661,
    -0.010482418644396214,
    -0.020516282176312236,
    0.0077289390737263625,
    0.00016356795647152401,
    0.006814789125185052,
    0.08762243808268254,
    -0.02773777924922762,
    -0.015711296720871175,
    0.023839840617649304,
    0.0666902704697932,
    -0.005637669873108077,
    0.101345331671057,
    -0.005292763384323931,
    -0.004250201955201913,
    0.0035591919851940493,
    0.06890211568383095,
    -0.025741169067397998,
    0.006106039787676133,
    0.02373681364562944,
    -0.028191765188999116
  ],
  "episode_returns": [
    1.2068951085702384,
    0.8526775673981524,
    0.615264767819701,
    -0.15945903017191565,
    -0.037818427073221805,
    0.43246973373793907,
    -0.39746378387307546,
    0.12172630903752868,
    0.19421909275592064,
    -0.060077114930856546,
    -0.10482418644396363,
    -0.2051628217631274,
    0.07728939073725627,
    0.0016356795647043398,
    0.06814789125184628,
    0.8762243808268178,
    -0.2773777924922727,
    -0.1571129672087168,
    0.23839840617649877,
    0.6669027046979359,
    -0.05637669873108653,
    1.0134533167105664,
    -0.052927633843236066,
    -0.04250201955201538,
    0.035591919851940546,
    0.6890211568383098,
    -0.25741169067398095,
    0.06106039787676654,
    0.23736813645629518,
    -0.28191765188999574
  ],
  "episode_lengths": [
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273,
    273
  ],
  "training_metrics": [
    {
      "loss": 0.4792577102780342,
      "policy_loss": 0.0020001139491796494,
      "value_loss": 0.4881938397884369,
      "entropy": 1.093624770641327
    },
    {
      "loss": 0.41133999824523926,
      "policy_loss": -0.02122888620942831,
      "value_loss": 0.4434582144021988,
      "entropy": 1.088932752609253
    },
    {
      "loss": 0.4973655641078949,
      "policy_loss": 0.015859394799917936,
      "value_loss": 0.49240458756685257,
      "entropy": 1.089841604232788
    }
  ]
}